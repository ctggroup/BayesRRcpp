---
title: "small manual"
author: "Daniel Trejo Banos"
date: "05/12/2017"
output: html_document
---

## Current Bayes R implementation

The current package prototype is an implementation of BayesR (citation ). It was developed in C++ 11.0 with interface to R through Rcpp. For numeric and matrix computations the library Eigen was used, along with it's R interface. The implementation has the following caveats:

- the random effects coefficients are sampled from four distributions in a mixture. the mixture variances are 0, 0.01, 0.001 and 0.0001 times the parameter $\sigma_{G}$. for now, the mixture components are hardcoded as 0, 0.01, 0.001 and 0.0001, but that can be changed as an additional parameter in the near future.
- the random effects are sampled all at once, by performing the cholesky decomposition of the matrix $X'X+D$ where D is the diagonal matrix containing the mixture variances. Said decomposition has a $\mathcal{O}\left( M^3\right)$ complexity (where M is the number of effects). There are many ways to reduce said complexity, like conditioning in subsets of effects or augmented variable sampling(none which has been implemented yet).
- Even though the function contains parameters for burnin time and thinning, the functionality hasnt been implemented yet, so you will be returned the total numner of samples given by the argument max_iterations. 
- It is contemplated to have a parallel process storing the samples in a file while the sampler does his thing, this functionality will be implemented very soon, but meanwhile, keep in mind that ALL the samples will be sotred into memory.

Having said that, proceed as following after having cloned the repository, go to the project folder and run:

 R CMD INSTALL --no-multiarch --with-keep.source BayesRRcpp

alternatively from Rstudio open the file BayesRRcpp.Rproj

then in the upper right pannel, on the tab "build" press the button "build and reload"

It may be necessary to install the packages Rcpp and RcppEigen.

if build was succesful, we will be to use the command

```{r}
library(BayesRRcpp)

```



Then for the standard BayesR model we have the function

```{bash,eval=F}
BayesRSampler(std::string outputFile, int seed, int max_iterations, int burn_in, int thinning, Eigen::MatrixXd X, Eigen::VectorXd Y,double sigma0, double v0E, double s02E, double v0G, double s02G, int B)
```

where 

outputFile = File in which post burn_in samples will be saved. A dedicated thread is in charge of saving the samples as their are being produced using a concurrent queue, as such the memory overhead is expected to be low. The number of saved samples will be max_iterations-burn_in. I haven't put much effort on validating the file pahts and so on, for now I recommend suing only the file name, as such the output will be saved in the directory returned by getwd().

seed= random seed; not functional for now

max_iterations= number of samples

burn_in= burn in samples, it has to be an integer lower than max_iterations. 

thinning= thinning regime; not implemented yet

X= matrix of markers (columns) and individuals(rows)

Y= matrix of phenotypes (columns) and individuals(rows); if Y has more than one column, use the function BayesRSamplerM instead (which is slower).

sigma0 = variance of the prior over the random intercept, $\mu \sim \mathcal{N}\left(0,\sigma_0\right) $. Set to a weakly informative value of 0.01, if set to 0 then the prior becoms a noninformative uniform distribution.

v0E,s02E=  degrees of freedom and variance of the prior scaled inverse chi square distribution over $\sigma_{E}$, set to a weakly informative value of 0.01

v0G,s02G=  degrees of freedom and variance of the prior scaled inverse chi square distribution over $\sigma_{G}$, set to a weakly informative value of 0.01

B = number of blocks in which the random effects will be sampled, for example for 1000 effects, a value B of 10 will involve 10 blocks of 100 effects conditionally drawn from a multivariate normal, which will involve a cholesky decomposition of a 100X100 matrix. We are reducing the size of matrix inversion in exchange of more computation (more matrix multiplications and more matrix inversions).

Additional note: The current implementation relies on preprocessing and storing on memory the scatter matrix $ X^TX$. It is possible to evaluate this matrix block by block during sampling, thus reducing memory consumption but greatly increasing processing required. Depending on the performance tests we may chose one or the other.


```{r,message=F,warning=F}
library(BayesRRcpp)
M=100
N=1000
B=matrix(rnorm(M,sd=0.1),ncol=1)
B[sample(1:100,30),1]=0#we randomly set 30 effects to zero
  X <- matrix(rnorm(M*N), N, M)
  Y=X%*%B+rnorm(N,sd=0.1)
 ## seems that scaling is detrimental to the fit when there are some zero coefficients?
  # Y=scale(Y)
  #X=scale(X)

 BayesRSampler("./test1.csv",1, 30000, 29000,1,X, Y,0.01,0.01,0.01,0.01,0.01,10)
       library(readr)
       tmp <- read_csv("./test1.csv")
        #names(tmp)
        #plot(tmp$sigmaG); mean(tmp$sigmaG)
       plot(B,colMeans(tmp[,grep("beta",names(tmp))]))
        lines(B,B)
        abline(h=0)

M=100
N=2000
B=matrix(rnorm(M,sd=sqrt(0.5/M)),ncol=1)
  X <- matrix(rnorm(M*N), N, M); var(X[,1])
    G <- X%*%B; var(G)
      Y=X%*%B+rnorm(N,sd=sqrt(1-var(G))); var(Y)
      Y=scale(Y)
      X=scale(X)
       BayesRSampler("test2.csv",1, 30000, 29000,1,X, Y,0.01,0.01,0.01,0.01,0.01,2)
       library(readr)
       tmp <- read_csv("./test2.csv")
        #names(tmp)
        #plot(tmp$sigmaG); mean(tmp$sigmaG)
       plot(B,colMeans(tmp[,grep("beta",names(tmp))]))
        lines(B,B)
        abline(h=0)
         var(G)
        mean(tmp$EV)
         1-var(G)
         mean(tmp$sigmaE)
         
```

the sampler outputs a matrix whose columns are

beta= random effects $\beta$

sigmaG= genetic effects variance $\sigma_{G}$

components= component of the mixture from which each $\beta$ was drawn from.

sigmaE = residuals variance $\sigma_{E}$

pi= mixing proportions $\pi$

mu= random intercept parameter $\mu$

EV = explained variance as computed: $\mathrm{var} \left(X\beta\right)$ , for each sample of $\beta$ 

each row contains a post burn_in set of samples for the variables.

## Installation on cluster

to install the package on the cluster:

go to your home directory (~/) and create a directory for the repository, then use git (already installed as part of vital it)

```{bash,eval = F}
git clone https://github.com/ctggroup/BayesRRcpp.git
```

now change create a directory in your home directory (if it doesnt exist)

```{bash,eval=F}
mkdir ~/.R
```

and create a Makevars file telling R to compile using  C++11 and support for multi threading

```{bash,eval=F}
echo 'CXXFLAGS += -std=gnu++11 -fopenmp'> ~/.R/Makevars
```

finally change to the PARENT DIRECTORY in which BayesRRcpp is contained, for example, if BayesRRcpp is in ~/repo/BayesRRcpp change to ~/repo/

there execute

```{bash,eval=F}
module add R/3.3.2
```

now you can start your R session

```{bash, eval=F}
R

```


Given that bayes Rcpp requires packages "Rcpp" and "RcppEigen" we are going to install them. We wont be able to install them globally but R will ask you to install them locally in your home directory

```{r,eval=F}
install.packages("Rcpp")
install.packages("RcppEigen")

```

close your R session, and exectue the following command

```{bash,eval=F}
R CMD build BayesRRcpp
R CMD INSTALL --preclean --no-multiarch --with-keep.source BayesRRcpp
```

and now, assuming the build and installation succeeded you will be able to call BayesRcpp directly as a library

```{r,eval=F}
library(BayesRRcpp)
```


## Installation on MAC

in order to compile openMP programs on a mac we require to install llvm and its clang compiler. We will use homebrew:

https://brew.sh/index_en.html

After installing homebrew we will use it to install llvm (it will take a while):

```{bash,eval=F}
brew install --with-toolchain llvm
```

Now in order to use the new clang compiler in R studio it is necessary to create the file Makevars in your home directory

```{bash,eval=F}
mkdir ~/.R/
vi Makevars
```

The file must contain the following lines 

```{bash,eval=F}
CXX="/usr/local/opt/llvm/bin/clang"
CPPFLAGS +=  -std=c++11 -fopenmp -idirafter /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/
LDFLAGS+= -L/usr/local/opt/llvm/lib
```

CXX flag tell us to use the llvm clang compiler
CPPFLAGS tell us to use C++11 openmp and the header files from Xcode.
LDFLAGS tell us to use the lib files from llvm.

hopefully set up wont vary much depending on your OSX version.
